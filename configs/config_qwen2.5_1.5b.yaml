# Complete training config for Qwen2.5-3B Diffusion Model
#
# Usage:
#   # Train with random weights (architecture only):
#   python train.py --config-name config_qwen2.5_0.5b
#
#   # Train with pretrained weights (download first):
#   litgpt download Qwen/Qwen2.5-3B
#   python train.py --config-name config_qwen2.5_0.5b model.checkpoint_dir=checkpoints/Qwen/Qwen2.5-3B

defaults:
  - model: qwen2.5_1.5b
  - data: shakespeare  # Change to your dataset
  - training: default
  - tokenizer: qwen2.5
  - _self_

seed: 42

# Override training params for finetuning pretrained model
training:
  epochs: 10  # Fewer epochs for finetuning
  save_dir: ${hydra:runtime.output_dir}/qwen2.5_1.5b_diffusion
  val_generation_freq: 2  # Generate samples every 2 epochs

# WandB logger
logger:
 _target_: lightning.pytorch.loggers.WandbLogger
 entity: tiny-zero-diffusion
 project: diffusion_lm
 name: ${oc.select:experiment_suffix,null}